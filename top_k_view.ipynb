{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=====> cph\n",
      "=====> sf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/s3155900/.local/lib/python3.8/site-packages/numpy/core/_asarray.py:102: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  return array(a, dtype, copy=False, order=order)\n"
     ]
    }
   ],
   "source": [
    "from gcl_sem.libs.mapillary_sls.mapillary_sls.datasets.msls import MSLS\n",
    "msls_root=\"/deepstore/datasets/dmb/ComputerVision/nis-data/acvpr-msls\"\n",
    "msls_dataset = MSLS(msls_root, \"\", mode=\"val\", posDistThr=25)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def key_from_path(path):\n",
    "    return path.split(\"/\")[-1].split(\".\")[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "740\n"
     ]
    }
   ],
   "source": [
    "query_keys = [\n",
    "    key_from_path(msls_dataset.qImages[q_idx]) for q_idx in msls_dataset.qIdx\n",
    "]\n",
    "\n",
    "positive_keys = [\n",
    "    [key_from_path(msls_dataset.dbImages[pos_idx]) for pos_idx in pos_indexes]\n",
    "    for pos_indexes in msls_dataset.pIdx\n",
    "]\n",
    "\n",
    "print(len(query_keys))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall:  0.7094594594594594\n"
     ]
    }
   ],
   "source": [
    "# top_k_file = \"/home/s3155900/gregory/utwente-acvpr-gcl_sem/runs/gcl_channels/run_3/top_k_20.json\"\n",
    "    # \"/home/s3155900/gregory/utwente-acvpr-gcl_sem/runs/gcl_channels/run_3/top_k_10.json\"\n",
    "top_k_file = \"/home/s3155900/gregory/utwente-acvpr-gcl_sem/runs/gcl_normal/run_2/top_k_0.txt\"\n",
    "\n",
    "\n",
    "with open(top_k_file) as f:\n",
    "    preds = {\n",
    "        query: matches\n",
    "        for query, *matches in [line.strip().split() for line in f.readlines()]\n",
    "    }\n",
    "\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "cph_path = \"/deepstore/datasets/dmb/ComputerVision/nis-data/acvpr-msls/train_val/cph\"\n",
    "sf_path = \"/deepstore/datasets/dmb/ComputerVision/nis-data/acvpr-msls/train_val/sf\"\n",
    "\n",
    "# key to image path\n",
    "cph_images = {}\n",
    "for root, dirs, files in os.walk(cph_path):\n",
    "    for file in files:\n",
    "        if file.endswith(\".jpg\"):\n",
    "            # get filename without path and extension\n",
    "            key = os.path.splitext(os.path.basename(file))[0]\n",
    "\n",
    "            cph_images[key] = os.path.join(root, file)\n",
    "\n",
    "sf_images = {}\n",
    "for root, dirs, files in os.walk(sf_path):\n",
    "    for file in files:\n",
    "        if file.endswith(\".jpg\"):\n",
    "            # get filename without path and extension\n",
    "            key = os.path.splitext(os.path.basename(file))[0]\n",
    "\n",
    "            sf_images[key] = os.path.join(root, file)\n",
    "\n",
    "\n",
    "all_images = {**cph_images, **sf_images}\n",
    "\n",
    "accurate_matches = {\n",
    "    query: [match for match in matches if match in positive_keys[i]]\n",
    "    for i, (query, matches) in enumerate(preds.items())\n",
    "}\n",
    "\n",
    "query_keys_sorted_by_nb_matches = sorted(\n",
    "    accurate_matches.keys(), key=lambda k: len(accurate_matches[k]), reverse=True\n",
    ")\n",
    "\n",
    "\n",
    "recall = []\n",
    "# for each predictions, check if any of the first 20 matches is in the positive keys\n",
    "for query, matches in preds.items():\n",
    "    query_idx = query_keys.index(query)\n",
    "\n",
    "    has_match = False\n",
    "    for match in matches[0:20]:\n",
    "        if match in positive_keys[query_idx]:\n",
    "            has_match = True\n",
    "            break\n",
    "\n",
    "\n",
    "    if has_match:\n",
    "        recall.append(1)\n",
    "    else:\n",
    "        recall.append(0)\n",
    "\n",
    "print(\"Recall: \", np.mean(recall))\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "32ecfcbb42c949acaf3383b28c4bef80",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=0, description='index', max=739), Output()), _dom_classes=('widget-interâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<function __main__.show_top_k(index=0)>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "from code import interact\n",
    "\n",
    "def show_top_k(index=0):\n",
    "    query = query_keys_sorted_by_nb_matches[index]\n",
    "    matches = preds[query]\n",
    "\n",
    "    query_image = all_images[query]\n",
    "    \n",
    "    correct_matches = accurate_matches[query]\n",
    "\n",
    "    print(f\"Query image: {query}\")\n",
    "    print(f\"Correct matches: {len(correct_matches)}\")\n",
    "    for c in correct_matches:\n",
    "        print(f\"  {c}\")\n",
    "    \n",
    "    img = Image.open(query_image)\n",
    "    plt.imshow(img)\n",
    "    plt.axis(\"off\")\n",
    "    plt.show()\n",
    "\n",
    "    # create a subplot for each match\n",
    "    fig, axs = plt.subplots(5, 5)\n",
    "\n",
    "    # make figure bigger\n",
    "    fig.set_figwidth(20)\n",
    "    fig.set_figheight(15)\n",
    "\n",
    "    # find the matches\n",
    "    for i, match in enumerate(matches):\n",
    "        if match in all_images:\n",
    "            match_image = all_images[match]\n",
    "        else:\n",
    "            print(f\"Could not find image for {match}\")\n",
    "            continue\n",
    "        \n",
    "        img = Image.open(match_image)\n",
    "        img = np.array(img)\n",
    "\n",
    "        border_size = 20\n",
    "        if match in correct_matches:\n",
    "            axs[i // 5, i % 5].set_title(f\"Correct\")\n",
    "\n",
    "            border_color = [0, 255, 0]\n",
    "        else:\n",
    "            axs[i // 5, i % 5].set_title(\"Incorrect\")\n",
    "            border_color = [255, 0, 0]\n",
    "\n",
    "        img[:border_size, :, :] = border_color\n",
    "        img[-border_size:, :, :] = border_color\n",
    "        img[:, :border_size, :] = border_color\n",
    "        img[:, -border_size:, :] = border_color\n",
    "        \n",
    "        axs[i // 5, i % 5].imshow(img)\n",
    "\n",
    "        # remove axis\n",
    "        axs[i // 5, i % 5].axis(\"off\")\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "from ipywidgets import interact\n",
    "\n",
    "interact(show_top_k, index=(0, len(preds) - 1))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
